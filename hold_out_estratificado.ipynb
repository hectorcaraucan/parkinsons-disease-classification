{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52tAA5GBuWjj",
        "outputId": "3fb0f86e-4e39-4607-987c-c17e6291daea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo 'parkinsons_data.csv' cargado exitosamente.\n",
            "--- Información General del DataFrame ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 195 entries, 0 to 194\n",
            "Data columns (total 24 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   name              195 non-null    int64  \n",
            " 1   MDVP:Fo(Hz)       195 non-null    float64\n",
            " 2   MDVP:Fhi(Hz)      195 non-null    float64\n",
            " 3   MDVP:Flo(Hz)      195 non-null    float64\n",
            " 4   MDVP:Jitter(%)    195 non-null    float64\n",
            " 5   MDVP:Jitter(Abs)  195 non-null    float64\n",
            " 6   MDVP:RAP          195 non-null    float64\n",
            " 7   MDVP:PPQ          195 non-null    float64\n",
            " 8   Jitter:DDP        195 non-null    float64\n",
            " 9   MDVP:Shimmer      195 non-null    float64\n",
            " 10  MDVP:Shimmer(dB)  195 non-null    float64\n",
            " 11  Shimmer:APQ3      195 non-null    float64\n",
            " 12  Shimmer:APQ5      195 non-null    float64\n",
            " 13  MDVP:APQ          195 non-null    float64\n",
            " 14  Shimmer:DDA       195 non-null    float64\n",
            " 15  NHR               195 non-null    float64\n",
            " 16  HNR               195 non-null    float64\n",
            " 17  RPDE              195 non-null    float64\n",
            " 18  DFA               195 non-null    float64\n",
            " 19  spread1           195 non-null    float64\n",
            " 20  spread2           195 non-null    float64\n",
            " 21  D2                195 non-null    float64\n",
            " 22  PPE               195 non-null    float64\n",
            " 23  status            195 non-null    int64  \n",
            "dtypes: float64(22), int64(2)\n",
            "memory usage: 36.7 KB\n",
            "\n",
            "\n",
            "--- Primeras 5 filas del DataFrame ---\n",
            "   name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
            "0     1      119.992       157.302        74.997         0.00784   \n",
            "1     2      122.400       148.650       113.819         0.00968   \n",
            "2     3      116.682       131.111       111.555         0.01050   \n",
            "3     4      116.676       137.871       111.366         0.00997   \n",
            "4     5      116.014       141.781       110.655         0.01284   \n",
            "\n",
            "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
            "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
            "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
            "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
            "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
            "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
            "\n",
            "   Shimmer:DDA      NHR     HNR      RPDE       DFA   spread1   spread2  \\\n",
            "0      0.06545  0.02211  21.033  0.414783  0.815285 -4.813031  0.266482   \n",
            "1      0.09403  0.01929  19.085  0.458359  0.819521 -4.075192  0.335590   \n",
            "2      0.08270  0.01309  20.651  0.429895  0.825288 -4.443179  0.311173   \n",
            "3      0.08771  0.01353  20.644  0.434969  0.819235 -4.117501  0.334147   \n",
            "4      0.10470  0.01767  19.649  0.417356  0.823484 -3.747787  0.234513   \n",
            "\n",
            "         D2       PPE  status  \n",
            "0  2.301442  0.284654       1  \n",
            "1  2.486855  0.368674       1  \n",
            "2  2.342259  0.332634       1  \n",
            "3  2.405554  0.368975       1  \n",
            "4  2.332180  0.410335       1  \n",
            "\n",
            "[5 rows x 24 columns]\n",
            "\n",
            "--- Verificación de Valores Perdidos ---\n",
            "No se encontraron valores perdidos en el DataSet.\n",
            "\n",
            "--- Verificación de Desbalance de Clases ---\n",
            "Distribución de clases en la columna 'status':\n",
            "status\n",
            "1    147\n",
            "0     48\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Porcentaje Clase 0: 24.62%\n",
            "Porcentaje Clase 1: 75.38%\n",
            "\n",
            "Conclusión: El DataSet está desbalanceado.\n"
          ]
        }
      ],
      "source": [
        "# Celda 1: Importar bibliotecas y cargar datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import csv\n",
        "\n",
        "# Cargar el conjunto de datos\n",
        "try:\n",
        "    df = pd.read_csv('parkinsons_data.csv')\n",
        "    print(\"Archivo 'parkinsons_data.csv' cargado exitosamente.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Asegúrate de haber subido el archivo 'parkinsons_data.csv' a Google Colab.\")\n",
        "\n",
        "# Celda 2: Inspección inicial del DataFrame\n",
        "print(\"--- Información General del DataFrame ---\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\n\\n--- Primeras 5 filas del DataFrame ---\")\n",
        "print(df.head())\n",
        "\n",
        "# Celda 3: Tarea 1.1 - Verificar valores perdidos\n",
        "print(\"\\n--- Verificación de Valores Perdidos ---\")\n",
        "valores_perdidos = df.isnull().sum()\n",
        "if valores_perdidos.sum() == 0:\n",
        "    print(\"No se encontraron valores perdidos en el DataSet.\")\n",
        "else:\n",
        "    print(\"Se encontraron los siguientes valores perdidos por columna:\")\n",
        "    print(valores_perdidos[valores_perdidos > 0])\n",
        "\n",
        "# Celda 4: Tarea 1.2 - Verificar desbalance de clases\n",
        "print(\"\\n--- Verificación de Desbalance de Clases ---\")\n",
        "# Asumimos que la columna 'status' es la clase. Si es otra, se debe cambiar aquí.\n",
        "columna_clase = 'status'\n",
        "conteo_clases = df[columna_clase].value_counts()\n",
        "print(f\"Distribución de clases en la columna '{columna_clase}':\")\n",
        "print(conteo_clases)\n",
        "\n",
        "total_muestras = len(df)\n",
        "porcentaje_clase_0 = (conteo_clases[0] / total_muestras) * 100\n",
        "porcentaje_clase_1 = (conteo_clases[1] / total_muestras) * 100\n",
        "\n",
        "print(f\"\\nPorcentaje Clase 0: {porcentaje_clase_0:.2f}%\")\n",
        "print(f\"Porcentaje Clase 1: {porcentaje_clase_1:.2f}%\")\n",
        "\n",
        "if abs(porcentaje_clase_0 - porcentaje_clase_1) > 20: # Umbral del 20% de diferencia\n",
        "    print(\"\\nConclusión: El DataSet está desbalanceado.\")\n",
        "else:\n",
        "    print(\"\\nConclusión: El DataSet parece estar razonablemente balanceado.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 5: Preparación de Datos\n",
        "# Eliminar la columna 'name' ya que no es una característica numérica para el modelo\n",
        "if 'name' in df.columns:\n",
        "    df = df.drop(columns=['name'])\n",
        "\n",
        "# Separar características (X) y la etiqueta (y)\n",
        "X = df.drop(columns=[columna_clase]).values\n",
        "y = df[columna_clase].values\n",
        "\n",
        "# Celda 6: Implementación de Funciones y Clases desde Cero\n",
        "\n",
        "# --- Normalizador de Datos ---\n",
        "# Es crucial para que los algoritmos de redes neuronales converjan adecuadamente.\n",
        "def min_max_scaler(data):\n",
        "    min_vals = data.min(axis=0)\n",
        "    max_vals = data.max(axis=0)\n",
        "    # Evitar división por cero si una columna tiene el mismo valor en todas las filas\n",
        "    range_vals = np.where(max_vals - min_vals == 0, 1, max_vals - min_vals)\n",
        "    scaled_data = (data - min_vals) / range_vals\n",
        "    return scaled_data, min_vals, range_vals\n",
        "\n",
        "def scale_test_data(data, min_vals, range_vals):\n",
        "    return (data - min_vals) / range_vals\n",
        "\n",
        "# --- Función de Segmentación: Hold-Out Estratificado ---\n",
        "def stratified_hold_out_split(X, y, test_size=0.2, random_state=None):\n",
        "    if random_state is not None:\n",
        "        random.seed(random_state)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = [], [], [], []\n",
        "    indices_por_clase = {clase: [i for i, label in enumerate(y) if label == clase] for clase in np.unique(y)}\n",
        "\n",
        "    for clase, indices in indices_por_clase.items():\n",
        "        random.shuffle(indices)\n",
        "        n_test = int(len(indices) * test_size)\n",
        "        indices_test = indices[:n_test]\n",
        "        indices_train = indices[n_test:]\n",
        "\n",
        "        X_test.extend(X[indices_test])\n",
        "        y_test.extend(y[indices_test])\n",
        "        X_train.extend(X[indices_train])\n",
        "        y_train.extend(y[indices_train])\n",
        "\n",
        "    return np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)\n",
        "\n",
        "# --- Implementación del Perceptrón Multicapa (MLP) ---\n",
        "class MLP_Desde_Cero:\n",
        "    def __init__(self, tam_capas, tasa_aprendizaje=0.01, epocas=300):\n",
        "        # tam_capas es una lista, ej: [n_entradas, n_oculta1, n_salida]\n",
        "        self.tam_capas = tam_capas\n",
        "        self.tasa_aprendizaje = tasa_aprendizaje\n",
        "        self.epocas = epocas\n",
        "        self.pesos = []\n",
        "        self.sesgos = []\n",
        "\n",
        "        # Inicialización de pesos y sesgos\n",
        "        for i in range(len(tam_capas) - 1):\n",
        "            # Se inicializan los pesos con valores aleatorios pequeños para romper la simetría\n",
        "            w = np.random.randn(tam_capas[i], tam_capas[i+1]) * 0.1\n",
        "            b = np.zeros((1, tam_capas[i+1]))\n",
        "            self.pesos.append(w)\n",
        "            self.sesgos.append(b)\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        # Función de activación sigmoide, útil para capas de salida en clasificación binaria\n",
        "        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
        "\n",
        "    def _sigmoid_derivada(self, x):\n",
        "        # Derivada de la sigmoide, necesaria para la retropropagación\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def _forward_pass(self, X):\n",
        "        # Propagación hacia adelante\n",
        "        activaciones = [X]\n",
        "        entrada_capa = X\n",
        "        for i in range(len(self.pesos)):\n",
        "            salida_lineal = np.dot(entrada_capa, self.pesos[i]) + self.sesgos[i]\n",
        "            activacion = self._sigmoid(salida_lineal)\n",
        "            activaciones.append(activacion)\n",
        "            entrada_capa = activacion\n",
        "        return activaciones\n",
        "\n",
        "    def _backward_pass(self, y, activaciones):\n",
        "        # Retropropagación del error para calcular gradientes\n",
        "        errores = [y.reshape(-1, 1) - activaciones[-1]]\n",
        "        deltas = [errores[-1] * self._sigmoid_derivada(activaciones[-1])]\n",
        "\n",
        "        # Iterar hacia atrás desde la penúltima capa\n",
        "        for i in range(len(activaciones) - 2, 0, -1):\n",
        "            error = np.dot(deltas[0], self.pesos[i].T)\n",
        "            delta = error * self._sigmoid_derivada(activaciones[i])\n",
        "            deltas.insert(0, delta)\n",
        "\n",
        "        return deltas\n",
        "\n",
        "    def _actualizar_pesos(self, activaciones, deltas):\n",
        "        # Actualizar pesos y sesgos usando los gradientes calculados\n",
        "        for i in range(len(self.pesos)):\n",
        "            self.pesos[i] += np.dot(activaciones[i].T, deltas[i]) * self.tasa_aprendizaje\n",
        "            self.sesgos[i] += np.sum(deltas[i], axis=0, keepdims=True) * self.tasa_aprendizaje\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        for _ in range(self.epocas):\n",
        "            activaciones = self._forward_pass(X)\n",
        "            deltas = self._backward_pass(y, activaciones)\n",
        "            self._actualizar_pesos(activaciones, deltas)\n",
        "\n",
        "    def predict(self, X):\n",
        "        activaciones = self._forward_pass(X)\n",
        "        # La predicción es la salida de la última capa\n",
        "        predicciones_prob = activaciones[-1]\n",
        "        # Convertir probabilidades a clases binarias (0 o 1)\n",
        "        predicciones_clase = [1 if p > 0.5 else 0 for p in predicciones_prob]\n",
        "        return np.array(predicciones_clase)\n",
        "\n",
        "# --- Implementación de K-Nearest Neighbors (KNN) ---\n",
        "class KNN_Desde_Cero:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def _distancia_euclidiana(self, p1, p2):\n",
        "        # Cálculo de la distancia entre dos puntos\n",
        "        return np.sqrt(np.sum((p1 - p2)**2))\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        # En KNN, \"fit\" solo significa memorizar los datos de entrenamiento\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predicciones = []\n",
        "        for punto_test in X_test:\n",
        "            # Calcular distancias a todos los puntos de entrenamiento\n",
        "            distancias = [self._distancia_euclidiana(punto_test, punto_train) for punto_train in self.X_train]\n",
        "            # Obtener los índices de los k vecinos más cercanos\n",
        "            indices_vecinos = np.argsort(distancias)[:self.k]\n",
        "            # Obtener las etiquetas de esos vecinos\n",
        "            etiquetas_vecinos = [self.y_train[i] for i in indices_vecinos]\n",
        "            # Predecir por voto de mayoría\n",
        "            prediccion = max(set(etiquetas_vecinos), key=etiquetas_vecinos.count)\n",
        "            predicciones.append(prediccion)\n",
        "        return np.array(predicciones)\n",
        "\n",
        "# --- Métricas de Desempeño ---\n",
        "def calcular_metricas(y_true, y_pred):\n",
        "    # Calcula TP, TN, FP, FN\n",
        "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
        "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
        "\n",
        "    # Calcula métricas, con manejo de división por cero\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0 # También llamado Sensibilidad\n",
        "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"Specificity\": specificity\n",
        "    }\n",
        "\n",
        "# Celda 7: Bucle de Ejecución para 30 Corridas\n",
        "print(\"\\n--- Iniciando 30 Corridas con Hold-Out Estratificado (80/20) ---\")\n",
        "\n",
        "# Parámetros\n",
        "N_CORRIDAS = 30\n",
        "N_ENTRADAS = X.shape[1]\n",
        "N_SALIDAS = 1\n",
        "\n",
        "# Estructuras para almacenar resultados de las 30 corridas\n",
        "resultados = {\n",
        "    \"MLP (10 neuronas)\": [], \"MLP (100 neuronas)\": [],\n",
        "    \"MLPDeep (10-10-10)\": [], \"MLPDeep (100-100-100)\": [],\n",
        "    \"KNN (k=3)\": [], \"KNN (k=5)\": [], \"KNN (k=27)\": []\n",
        "}\n",
        "\n",
        "for i in range(N_CORRIDAS):\n",
        "    print(f\"Iniciando corrida {i+1}/{N_CORRIDAS}...\")\n",
        "\n",
        "    # Segmentación estratificada\n",
        "    X_train, X_test, y_train, y_test = stratified_hold_out_split(X, y, test_size=0.2, random_state=i)\n",
        "\n",
        "    # Normalización\n",
        "    X_train_scaled, min_vals, range_vals = min_max_scaler(X_train)\n",
        "    X_test_scaled = scale_test_data(X_test, min_vals, range_vals)\n",
        "\n",
        "    # --- Modelos ---\n",
        "    # MLP (10 neuronas)\n",
        "    mlp_10 = MLP_Desde_Cero(tam_capas=[N_ENTRADAS, 10, N_SALIDAS])\n",
        "    mlp_10.fit(X_train_scaled, y_train)\n",
        "    preds = mlp_10.predict(X_test_scaled)\n",
        "    resultados[\"MLP (10 neuronas)\"].append(calcular_metricas(y_test, preds))\n",
        "\n",
        "    # MLP (100 neuronas)\n",
        "    mlp_100 = MLP_Desde_Cero(tam_capas=[N_ENTRADAS, 100, N_SALIDAS])\n",
        "    mlp_100.fit(X_train_scaled, y_train)\n",
        "    preds = mlp_100.predict(X_test_scaled)\n",
        "    resultados[\"MLP (100 neuronas)\"].append(calcular_metricas(y_test, preds))\n",
        "\n",
        "    # MLPDeep (3 capas ocultas, 10 neuronas c/u)\n",
        "    mlp_deep_10 = MLP_Desde_Cero(tam_capas=[N_ENTRADAS, 10, 10, 10, N_SALIDAS])\n",
        "    mlp_deep_10.fit(X_train_scaled, y_train)\n",
        "    preds = mlp_deep_10.predict(X_test_scaled)\n",
        "    resultados[\"MLPDeep (10-10-10)\"].append(calcular_metricas(y_test, preds))\n",
        "\n",
        "    # MLPDeep (3 capas ocultas, 100 neuronas c/u)\n",
        "    mlp_deep_100 = MLP_Desde_Cero(tam_capas=[N_ENTRADAS, 100, 100, 100, N_SALIDAS])\n",
        "    mlp_deep_100.fit(X_train_scaled, y_train)\n",
        "    preds = mlp_deep_100.predict(X_test_scaled)\n",
        "    resultados[\"MLPDeep (100-100-100)\"].append(calcular_metricas(y_test, preds))\n",
        "\n",
        "    # KNN (k=3, 5, 27) - Usa datos sin escalar\n",
        "    for k_val in [3, 5, 27]:\n",
        "        knn = KNN_Desde_Cero(k=k_val)\n",
        "        knn.fit(X_train, y_train)\n",
        "        preds = knn.predict(X_test)\n",
        "        resultados[f\"KNN (k={k_val})\"].append(calcular_metricas(y_test, preds))\n",
        "\n",
        "print(\"Ejecución de 30 corridas completada.\")\n",
        "\n",
        "# Celda 8: Cálculo de Estadísticas y Exportación\n",
        "print(\"\\n--- Calculando Estadísticas (Promedio, Mínimo, Máximo) ---\")\n",
        "estadisticas_finales = []\n",
        "\n",
        "for modelo, metricas_corridas in resultados.items():\n",
        "    df_metricas = pd.DataFrame(metricas_corridas)\n",
        "\n",
        "    promedio = df_metricas.mean().to_dict()\n",
        "    minimo = df_metricas.min().to_dict()\n",
        "    maximo = df_metricas.max().to_dict()\n",
        "\n",
        "    for metrica in [\"Accuracy\", \"Precision\", \"Recall\", \"Specificity\"]:\n",
        "        estadisticas_finales.append({\n",
        "            \"Validation\": \"Hold-Out-Stratified\",\n",
        "            \"Algorithm\": modelo,\n",
        "            \"Metric\": metrica,\n",
        "            \"Mean\": promedio[metrica],\n",
        "            \"Min\": minimo[metrica],\n",
        "            \"Max\": maximo[metrica]\n",
        "        })\n",
        "\n",
        "df_estadisticas = pd.DataFrame(estadisticas_finales)\n",
        "print(df_estadisticas)\n",
        "\n",
        "# Exportar a CSV para el llenado automático\n",
        "df_estadisticas.to_csv('hold_out_results.csv', index=False)\n",
        "print(\"\\nResultados guardados en 'hold_out_results.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDuaqudAv387",
        "outputId": "8ab936bb-1aca-4a7d-c663-92b6b48b9bdd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iniciando 30 Corridas con Hold-Out Estratificado (80/20) ---\n",
            "Iniciando corrida 1/30...\n",
            "Iniciando corrida 2/30...\n",
            "Iniciando corrida 3/30...\n",
            "Iniciando corrida 4/30...\n",
            "Iniciando corrida 5/30...\n",
            "Iniciando corrida 6/30...\n",
            "Iniciando corrida 7/30...\n",
            "Iniciando corrida 8/30...\n",
            "Iniciando corrida 9/30...\n",
            "Iniciando corrida 10/30...\n",
            "Iniciando corrida 11/30...\n",
            "Iniciando corrida 12/30...\n",
            "Iniciando corrida 13/30...\n",
            "Iniciando corrida 14/30...\n",
            "Iniciando corrida 15/30...\n",
            "Iniciando corrida 16/30...\n",
            "Iniciando corrida 17/30...\n",
            "Iniciando corrida 18/30...\n",
            "Iniciando corrida 19/30...\n",
            "Iniciando corrida 20/30...\n",
            "Iniciando corrida 21/30...\n",
            "Iniciando corrida 22/30...\n",
            "Iniciando corrida 23/30...\n",
            "Iniciando corrida 24/30...\n",
            "Iniciando corrida 25/30...\n",
            "Iniciando corrida 26/30...\n",
            "Iniciando corrida 27/30...\n",
            "Iniciando corrida 28/30...\n",
            "Iniciando corrida 29/30...\n",
            "Iniciando corrida 30/30...\n",
            "Ejecución de 30 corridas completada.\n",
            "\n",
            "--- Calculando Estadísticas (Promedio, Mínimo, Máximo) ---\n",
            "             Validation              Algorithm       Metric      Mean  \\\n",
            "0   Hold-Out-Stratified      MLP (10 neuronas)     Accuracy  0.838596   \n",
            "1   Hold-Out-Stratified      MLP (10 neuronas)    Precision  0.833905   \n",
            "2   Hold-Out-Stratified      MLP (10 neuronas)       Recall  0.988506   \n",
            "3   Hold-Out-Stratified      MLP (10 neuronas)  Specificity  0.355556   \n",
            "4   Hold-Out-Stratified     MLP (100 neuronas)     Accuracy  0.831579   \n",
            "5   Hold-Out-Stratified     MLP (100 neuronas)    Precision  0.853628   \n",
            "6   Hold-Out-Stratified     MLP (100 neuronas)       Recall  0.943678   \n",
            "7   Hold-Out-Stratified     MLP (100 neuronas)  Specificity  0.470370   \n",
            "8   Hold-Out-Stratified     MLPDeep (10-10-10)     Accuracy  0.763158   \n",
            "9   Hold-Out-Stratified     MLPDeep (10-10-10)    Precision  0.763158   \n",
            "10  Hold-Out-Stratified     MLPDeep (10-10-10)       Recall  1.000000   \n",
            "11  Hold-Out-Stratified     MLPDeep (10-10-10)  Specificity  0.000000   \n",
            "12  Hold-Out-Stratified  MLPDeep (100-100-100)     Accuracy  0.763158   \n",
            "13  Hold-Out-Stratified  MLPDeep (100-100-100)    Precision  0.763158   \n",
            "14  Hold-Out-Stratified  MLPDeep (100-100-100)       Recall  1.000000   \n",
            "15  Hold-Out-Stratified  MLPDeep (100-100-100)  Specificity  0.000000   \n",
            "16  Hold-Out-Stratified              KNN (k=3)     Accuracy  0.850877   \n",
            "17  Hold-Out-Stratified              KNN (k=3)    Precision  0.890113   \n",
            "18  Hold-Out-Stratified              KNN (k=3)       Recall  0.919540   \n",
            "19  Hold-Out-Stratified              KNN (k=3)  Specificity  0.629630   \n",
            "20  Hold-Out-Stratified              KNN (k=5)     Accuracy  0.852632   \n",
            "21  Hold-Out-Stratified              KNN (k=5)    Precision  0.876957   \n",
            "22  Hold-Out-Stratified              KNN (k=5)       Recall  0.941379   \n",
            "23  Hold-Out-Stratified              KNN (k=5)  Specificity  0.566667   \n",
            "24  Hold-Out-Stratified             KNN (k=27)     Accuracy  0.819298   \n",
            "25  Hold-Out-Stratified             KNN (k=27)    Precision  0.814134   \n",
            "26  Hold-Out-Stratified             KNN (k=27)       Recall  0.990805   \n",
            "27  Hold-Out-Stratified             KNN (k=27)  Specificity  0.266667   \n",
            "\n",
            "         Min       Max  \n",
            "0   0.763158  0.894737  \n",
            "1   0.763158  0.903226  \n",
            "2   0.896552  1.000000  \n",
            "3   0.000000  0.666667  \n",
            "4   0.736842  0.921053  \n",
            "5   0.783784  0.906250  \n",
            "6   0.827586  1.000000  \n",
            "7   0.111111  0.666667  \n",
            "8   0.763158  0.763158  \n",
            "9   0.763158  0.763158  \n",
            "10  1.000000  1.000000  \n",
            "11  0.000000  0.000000  \n",
            "12  0.763158  0.763158  \n",
            "13  0.763158  0.763158  \n",
            "14  1.000000  1.000000  \n",
            "15  0.000000  0.000000  \n",
            "16  0.736842  0.973684  \n",
            "17  0.827586  0.966667  \n",
            "18  0.793103  1.000000  \n",
            "19  0.444444  0.888889  \n",
            "20  0.763158  0.973684  \n",
            "21  0.812500  0.966667  \n",
            "22  0.862069  1.000000  \n",
            "23  0.333333  0.888889  \n",
            "24  0.710526  0.868421  \n",
            "25  0.750000  0.875000  \n",
            "26  0.931034  1.000000  \n",
            "27  0.000000  0.555556  \n",
            "\n",
            "Resultados guardados en 'hold_out_results.csv'\n"
          ]
        }
      ]
    }
  ]
}