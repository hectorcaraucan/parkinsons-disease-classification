# Parkinson's Disease Classification

![Python](https://img.shields.io/badge/Python-3.9+-blue?style=for-the-badge&logo=python&logoColor=white)
![Libraries](https://img.shields.io/badge/Libraries-Scikit--learn%2C%20Pandas%2C%20Numpy-orange?style=for-the-badge)

This project focuses on classifying patients with Parkinson's disease based on a range of biomedical voice measurements. The primary goal is to apply and evaluate various machine learning algorithms and cross-validation techniques to build a robust predictive model.

[cite_start]This project was developed as a practical exercise for the Master's in Artificial Intelligence program[cite: 12, 43].

---

## üìã Table of Contents
1.  [Project Overview](#project-overview)
2.  [Dataset](#dataset)
3.  [Methodology](#methodology)
4.  [Results](#results)
5.  [How to Run](#how-to-run)
6.  [File Structure](#file-structure)

---

## üìå Project Overview

Parkinson's disease is a neurodegenerative disorder that affects motor functions. Early diagnosis is crucial for treatment and management. This project leverages machine learning to distinguish between healthy individuals and those with Parkinson's by analyzing features extracted from voice recordings. The exercise specifically involves rigorous model validation and performance analysis.

## üìä Dataset

The dataset used is the popular "Parkinson's Disease" dataset from the UCI Machine Learning Repository.

- [cite_start]**Initial Analysis:** A preliminary analysis was conducted to check for missing values and class imbalance[cite: 46]. [cite_start]The project proceeds even with class imbalance to observe the impact on model performance, as per the exercise instructions[cite: 49].

---

## ‚öôÔ∏è Methodology

The core of this project is a structured comparison of different modeling approaches and validation strategies.

### 1. Data Preprocessing
- **Data Cleaning:** Assessed and handled any missing values.
- **Feature Scaling:** Applied standard scaling to normalize the feature set, ensuring that all features contribute equally to model training.

### 2. Model Training & Cross-Validation Techniques
[cite_start]To ensure the robustness and generalizability of the models, three distinct cross-validation methods were implemented in separate notebooks[cite: 47, 48]:

- [cite_start]**Stratified Hold-Out:** The data was split into 80% for training and 20% for testing, preserving the class distribution in both sets[cite: 47].
- [cite_start]**K-Fold Cross-Validation:** Performed with **k=10**, providing a robust estimate of model performance by training and testing on 10 different subsets of the data[cite: 47].
- **Leave-One-Out (LOO):** An exhaustive cross-validation where each data point is used as a test set once, ideal for smaller datasets.

### 3. Machine Learning Algorithms Implemented
[cite_start]The following algorithms were trained and evaluated[cite: 47]:

- **K-Nearest Neighbors (KNN):** With `k` values of 3, 5, and 27.
- **Multilayer Perceptron (MLP):**
    - A simple MLP with one hidden layer (testing between 10-100 neurons).
    - A deep MLP (`MLPDeepLearning`) with 3 hidden layers (testing between 10-100 neurons per layer).
- [cite_start]**Other Explored Algorithms:** My broader skill set also includes algorithms like **Support Vector Machines (SVM)** and **XGBoost**[cite: 5], which are excellent candidates for this type of classification task.

---

## üìà Results

Model performance was evaluated using a comprehensive set of metrics. [cite_start]For each algorithm and validation technique, the following were calculated over 30 independent runs to ensure statistical significance[cite: 47]:

- [cite_start]**Metrics:** Accuracy, Precision, Recall (Sensitivity), and Specificity[cite: 47].
- [cite_start]**Statistical Analysis:** The final results are presented in tables showing the **average, maximum, and minimum** values for each metric across the 30 runs[cite: 47, 51].

*(Note: The detailed statistical tables can be found in the final section of each Jupyter Notebook.)*

---

## üöÄ How to Run

To replicate the analysis, please follow these steps:

1.  **Prerequisites:**
    - Python 3.8+
    - Jupyter Notebook or JupyterLab
    - [cite_start]Libraries: `scikit-learn`, `pandas`, `numpy` [cite: 40]

2.  **Clone the repository:**
    ```bash
    git clone [https://github.com/hcaraucan/parkinsons-disease-classification.git](https://github.com/hcaraucan/parkinsons-disease-classification.git)
    cd parkinsons-disease-classification
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    *(Note: You will need to create a `requirements.txt` file listing the libraries).*

4.  **Run the notebooks:**
    Launch Jupyter and open one of the `.ipynb` files to see the implementation for each validation method.
    ```bash
    jupyter notebook
    ```

---

## üóÇÔ∏è File Structure

The repository is organized as follows:

‚îú‚îÄ‚îÄ parkinsons_hold_out.ipynb      # Notebook for the Stratified Hold-Out (80/20) method. 

‚îú‚îÄ‚îÄ parkinsons_k_fold_cv.ipynb     # Notebook for K-Fold Cross-Validation (k=10) method. 

‚îú‚îÄ‚îÄ parkinsons_leave_one_out.ipynb # Notebook for the Leave-One-Out method.
