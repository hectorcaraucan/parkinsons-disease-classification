{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2b6IdZaLHl9",
        "outputId": "918d8e3b-9142-4e44-d3b8-829c41a05930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo 'parkinsons_data.csv' cargado exitosamente.\n",
            "--- Información General del DataFrame ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 195 entries, 0 to 194\n",
            "Data columns (total 24 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   name              195 non-null    int64  \n",
            " 1   MDVP:Fo(Hz)       195 non-null    float64\n",
            " 2   MDVP:Fhi(Hz)      195 non-null    float64\n",
            " 3   MDVP:Flo(Hz)      195 non-null    float64\n",
            " 4   MDVP:Jitter(%)    195 non-null    float64\n",
            " 5   MDVP:Jitter(Abs)  195 non-null    float64\n",
            " 6   MDVP:RAP          195 non-null    float64\n",
            " 7   MDVP:PPQ          195 non-null    float64\n",
            " 8   Jitter:DDP        195 non-null    float64\n",
            " 9   MDVP:Shimmer      195 non-null    float64\n",
            " 10  MDVP:Shimmer(dB)  195 non-null    float64\n",
            " 11  Shimmer:APQ3      195 non-null    float64\n",
            " 12  Shimmer:APQ5      195 non-null    float64\n",
            " 13  MDVP:APQ          195 non-null    float64\n",
            " 14  Shimmer:DDA       195 non-null    float64\n",
            " 15  NHR               195 non-null    float64\n",
            " 16  HNR               195 non-null    float64\n",
            " 17  RPDE              195 non-null    float64\n",
            " 18  DFA               195 non-null    float64\n",
            " 19  spread1           195 non-null    float64\n",
            " 20  spread2           195 non-null    float64\n",
            " 21  D2                195 non-null    float64\n",
            " 22  PPE               195 non-null    float64\n",
            " 23  status            195 non-null    int64  \n",
            "dtypes: float64(22), int64(2)\n",
            "memory usage: 36.7 KB\n",
            "\n",
            "\n",
            "--- Primeras 5 filas del DataFrame ---\n",
            "   name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
            "0     1      119.992       157.302        74.997         0.00784   \n",
            "1     2      122.400       148.650       113.819         0.00968   \n",
            "2     3      116.682       131.111       111.555         0.01050   \n",
            "3     4      116.676       137.871       111.366         0.00997   \n",
            "4     5      116.014       141.781       110.655         0.01284   \n",
            "\n",
            "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
            "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
            "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
            "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
            "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
            "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
            "\n",
            "   Shimmer:DDA      NHR     HNR      RPDE       DFA   spread1   spread2  \\\n",
            "0      0.06545  0.02211  21.033  0.414783  0.815285 -4.813031  0.266482   \n",
            "1      0.09403  0.01929  19.085  0.458359  0.819521 -4.075192  0.335590   \n",
            "2      0.08270  0.01309  20.651  0.429895  0.825288 -4.443179  0.311173   \n",
            "3      0.08771  0.01353  20.644  0.434969  0.819235 -4.117501  0.334147   \n",
            "4      0.10470  0.01767  19.649  0.417356  0.823484 -3.747787  0.234513   \n",
            "\n",
            "         D2       PPE  status  \n",
            "0  2.301442  0.284654       1  \n",
            "1  2.486855  0.368674       1  \n",
            "2  2.342259  0.332634       1  \n",
            "3  2.405554  0.368975       1  \n",
            "4  2.332180  0.410335       1  \n",
            "\n",
            "[5 rows x 24 columns]\n",
            "\n",
            "--- Verificación de Valores Perdidos ---\n",
            "No se encontraron valores perdidos en el DataSet.\n",
            "\n",
            "--- Verificación de Desbalance de Clases ---\n",
            "Distribución de clases en la columna 'status':\n",
            "status\n",
            "1    147\n",
            "0     48\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Porcentaje Clase 0: 24.62%\n",
            "Porcentaje Clase 1: 75.38%\n",
            "\n",
            "Conclusión: El DataSet está desbalanceado.\n"
          ]
        }
      ],
      "source": [
        "# Celda 1: Importar bibliotecas y cargar datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import csv\n",
        "\n",
        "# Cargar el conjunto de datos\n",
        "try:\n",
        "    df = pd.read_csv('parkinsons_data.csv')\n",
        "    print(\"Archivo 'parkinsons_data.csv' cargado exitosamente.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Asegúrate de haber subido el archivo 'parkinsons_data.csv' a Google Colab.\")\n",
        "\n",
        "# Celda 2: Inspección inicial del DataFrame\n",
        "print(\"--- Información General del DataFrame ---\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\n\\n--- Primeras 5 filas del DataFrame ---\")\n",
        "print(df.head())\n",
        "\n",
        "# Celda 3: Tarea 1.1 - Verificar valores perdidos\n",
        "print(\"\\n--- Verificación de Valores Perdidos ---\")\n",
        "valores_perdidos = df.isnull().sum()\n",
        "if valores_perdidos.sum() == 0:\n",
        "    print(\"No se encontraron valores perdidos en el DataSet.\")\n",
        "else:\n",
        "    print(\"Se encontraron los siguientes valores perdidos por columna:\")\n",
        "    print(valores_perdidos[valores_perdidos > 0])\n",
        "\n",
        "# Celda 4: Tarea 1.2 - Verificar desbalance de clases\n",
        "print(\"\\n--- Verificación de Desbalance de Clases ---\")\n",
        "# Asumimos que la columna 'status' es la clase. Si es otra, se debe cambiar aquí.\n",
        "columna_clase = 'status'\n",
        "conteo_clases = df[columna_clase].value_counts()\n",
        "print(f\"Distribución de clases en la columna '{columna_clase}':\")\n",
        "print(conteo_clases)\n",
        "\n",
        "total_muestras = len(df)\n",
        "porcentaje_clase_0 = (conteo_clases[0] / total_muestras) * 100\n",
        "porcentaje_clase_1 = (conteo_clases[1] / total_muestras) * 100\n",
        "\n",
        "print(f\"\\nPorcentaje Clase 0: {porcentaje_clase_0:.2f}%\")\n",
        "print(f\"Porcentaje Clase 1: {porcentaje_clase_1:.2f}%\")\n",
        "\n",
        "if abs(porcentaje_clase_0 - porcentaje_clase_1) > 20: # Umbral del 20% de diferencia\n",
        "    print(\"\\nConclusión: El DataSet está desbalanceado.\")\n",
        "else:\n",
        "    print(\"\\nConclusión: El DataSet parece estar razonablemente balanceado.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 5: Preparación de Datos\n",
        "# Eliminar la columna 'name' ya que no es una característica numérica para el modelo\n",
        "if 'name' in df.columns:\n",
        "    df = df.drop(columns=['name'])\n",
        "\n",
        "# Separar características (X) y la etiqueta (y)\n",
        "X = df.drop(columns=[columna_clase]).values\n",
        "y = df[columna_clase].values\n",
        "\n",
        "# Celda 6: Implementación de Funciones y Clases desde Cero\n",
        "\n",
        "# --- Normalizador de Datos ---\n",
        "# Es crucial para que los algoritmos de redes neuronales converjan adecuadamente.\n",
        "def min_max_scaler(data):\n",
        "    min_vals = data.min(axis=0)\n",
        "    max_vals = data.max(axis=0)\n",
        "    # Evitar división por cero si una columna tiene el mismo valor en todas las filas\n",
        "    range_vals = np.where(max_vals - min_vals == 0, 1, max_vals - min_vals)\n",
        "    scaled_data = (data - min_vals) / range_vals\n",
        "    return scaled_data, min_vals, range_vals\n",
        "\n",
        "def scale_test_data(data, min_vals, range_vals):\n",
        "    return (data - min_vals) / range_vals\n",
        "\n",
        "# --- Función de Segmentación: Hold-Out Estratificado ---\n",
        "def stratified_hold_out_split(X, y, test_size=0.2, random_state=None):\n",
        "    if random_state is not None:\n",
        "        random.seed(random_state)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = [], [], [], []\n",
        "    indices_por_clase = {clase: [i for i, label in enumerate(y) if label == clase] for clase in np.unique(y)}\n",
        "\n",
        "    for clase, indices in indices_por_clase.items():\n",
        "        random.shuffle(indices)\n",
        "        n_test = int(len(indices) * test_size)\n",
        "        indices_test = indices[:n_test]\n",
        "        indices_train = indices[n_test:]\n",
        "\n",
        "        X_test.extend(X[indices_test])\n",
        "        y_test.extend(y[indices_test])\n",
        "        X_train.extend(X[indices_train])\n",
        "        y_train.extend(y[indices_train])\n",
        "\n",
        "    return np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test)\n",
        "\n",
        "# --- Implementación del Perceptrón Multicapa (MLP) ---\n",
        "class MLP_Desde_Cero:\n",
        "    def __init__(self, tam_capas, tasa_aprendizaje=0.01, epocas=300):\n",
        "        # tam_capas es una lista, ej: [n_entradas, n_oculta1, n_salida]\n",
        "        self.tam_capas = tam_capas\n",
        "        self.tasa_aprendizaje = tasa_aprendizaje\n",
        "        self.epocas = epocas\n",
        "        self.pesos = []\n",
        "        self.sesgos = []\n",
        "\n",
        "        # Inicialización de pesos y sesgos\n",
        "        for i in range(len(tam_capas) - 1):\n",
        "            # Se inicializan los pesos con valores aleatorios pequeños para romper la simetría\n",
        "            w = np.random.randn(tam_capas[i], tam_capas[i+1]) * 0.1\n",
        "            b = np.zeros((1, tam_capas[i+1]))\n",
        "            self.pesos.append(w)\n",
        "            self.sesgos.append(b)\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        # Función de activación sigmoide, útil para capas de salida en clasificación binaria\n",
        "        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
        "\n",
        "    def _sigmoid_derivada(self, x):\n",
        "        # Derivada de la sigmoide, necesaria para la retropropagación\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def _forward_pass(self, X):\n",
        "        # Propagación hacia adelante\n",
        "        activaciones = [X]\n",
        "        entrada_capa = X\n",
        "        for i in range(len(self.pesos)):\n",
        "            salida_lineal = np.dot(entrada_capa, self.pesos[i]) + self.sesgos[i]\n",
        "            activacion = self._sigmoid(salida_lineal)\n",
        "            activaciones.append(activacion)\n",
        "            entrada_capa = activacion\n",
        "        return activaciones\n",
        "\n",
        "    def _backward_pass(self, y, activaciones):\n",
        "        # Retropropagación del error para calcular gradientes\n",
        "        errores = [y.reshape(-1, 1) - activaciones[-1]]\n",
        "        deltas = [errores[-1] * self._sigmoid_derivada(activaciones[-1])]\n",
        "\n",
        "        # Iterar hacia atrás desde la penúltima capa\n",
        "        for i in range(len(activaciones) - 2, 0, -1):\n",
        "            error = np.dot(deltas[0], self.pesos[i].T)\n",
        "            delta = error * self._sigmoid_derivada(activaciones[i])\n",
        "            deltas.insert(0, delta)\n",
        "\n",
        "        return deltas\n",
        "\n",
        "    def _actualizar_pesos(self, activaciones, deltas):\n",
        "        # Actualizar pesos y sesgos usando los gradientes calculados\n",
        "        for i in range(len(self.pesos)):\n",
        "            self.pesos[i] += np.dot(activaciones[i].T, deltas[i]) * self.tasa_aprendizaje\n",
        "            self.sesgos[i] += np.sum(deltas[i], axis=0, keepdims=True) * self.tasa_aprendizaje\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        for _ in range(self.epocas):\n",
        "            activaciones = self._forward_pass(X)\n",
        "            deltas = self._backward_pass(y, activaciones)\n",
        "            self._actualizar_pesos(activaciones, deltas)\n",
        "\n",
        "    def predict(self, X):\n",
        "        activaciones = self._forward_pass(X)\n",
        "        # La predicción es la salida de la última capa\n",
        "        predicciones_prob = activaciones[-1]\n",
        "        # Convertir probabilidades a clases binarias (0 o 1)\n",
        "        predicciones_clase = [1 if p > 0.5 else 0 for p in predicciones_prob]\n",
        "        return np.array(predicciones_clase)\n",
        "\n",
        "# --- Implementación de K-Nearest Neighbors (KNN) ---\n",
        "class KNN_Desde_Cero:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def _distancia_euclidiana(self, p1, p2):\n",
        "        # Cálculo de la distancia entre dos puntos\n",
        "        return np.sqrt(np.sum((p1 - p2)**2))\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        # En KNN, \"fit\" solo significa memorizar los datos de entrenamiento\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predicciones = []\n",
        "        for punto_test in X_test:\n",
        "            # Calcular distancias a todos los puntos de entrenamiento\n",
        "            distancias = [self._distancia_euclidiana(punto_test, punto_train) for punto_train in self.X_train]\n",
        "            # Obtener los índices de los k vecinos más cercanos\n",
        "            indices_vecinos = np.argsort(distancias)[:self.k]\n",
        "            # Obtener las etiquetas de esos vecinos\n",
        "            etiquetas_vecinos = [self.y_train[i] for i in indices_vecinos]\n",
        "            # Predecir por voto de mayoría\n",
        "            prediccion = max(set(etiquetas_vecinos), key=etiquetas_vecinos.count)\n",
        "            predicciones.append(prediccion)\n",
        "        return np.array(predicciones)\n",
        "\n",
        "# --- Métricas de Desempeño ---\n",
        "def calcular_metricas(y_true, y_pred):\n",
        "    # Calcula TP, TN, FP, FN\n",
        "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
        "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
        "\n",
        "    # Calcula métricas, con manejo de división por cero\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0 # También llamado Sensibilidad\n",
        "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"Specificity\": specificity\n",
        "    }"
      ],
      "metadata": {
        "id": "PhQ3R895MGA-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 7: Lógica para Leave-One-Out Cross-Validation (LOOCV)\n",
        "# LOOCV es un caso especial de K-Fold donde k = N (número de muestras)\n",
        "print(\"\\n--- Iniciando Ejecución con Leave-One-Out (LOOCV) ---\")\n",
        "print(\"ADVERTENCIA: Este proceso es muy lento y puede tardar varias horas, especialmente para los modelos MLP.\")\n",
        "\n",
        "# Parámetros\n",
        "N_MUESTRAS = len(X)\n",
        "N_CORRIDAS_MLP = 30 # Para MLP por su inicialización aleatoria\n",
        "N_ENTRADAS = X.shape[1]\n",
        "N_SALIDAS = 1\n",
        "\n",
        "resultados_loocv = {\n",
        "    \"MLP (10 neuronas)\": [], \"MLP (100 neuronas)\": [],\n",
        "    \"MLPDeep (10-10-10)\": [], \"MLPDeep (100-100-100)\": [],\n",
        "    \"KNN (k=3)\": [], \"KNN (k=5)\": [], \"KNN (k=27)\": []\n",
        "}\n",
        "\n",
        "# --- Ejecución para KNN (solo 1 vez, es determinista) ---\n",
        "print(\"\\nIniciando LOOCV para modelos KNN...\")\n",
        "for k_val in [3, 5, 27]:\n",
        "    y_preds_knn = []\n",
        "    for i in range(N_MUESTRAS):\n",
        "        # Separar datos\n",
        "        X_test = X[i, :].reshape(1, -1)\n",
        "        y_test = y[i]\n",
        "        X_train = np.delete(X, i, axis=0)\n",
        "        y_train = np.delete(y, i, axis=0)\n",
        "\n",
        "        knn = KNN_Desde_Cero(k=k_val)\n",
        "        knn.fit(X_train, y_train)\n",
        "        pred = knn.predict(X_test)\n",
        "        y_preds_knn.append(pred[0])\n",
        "\n",
        "    # Calcular métricas una vez se tienen todas las predicciones\n",
        "    metricas = calcular_metricas(y, np.array(y_preds_knn))\n",
        "    resultados_loocv[f\"KNN (k={k_val})\"].append(metricas)\n",
        "print(\"LOOCV para KNN completado.\")\n",
        "\n",
        "# --- Ejecución para MLP (30 corridas) ---\n",
        "modelos_mlp_config = {\n",
        "    \"MLP (10 neuronas)\": {\"capas\": [N_ENTRADAS, 10, N_SALIDAS]},\n",
        "    \"MLP (100 neuronas)\": {\"capas\": [N_ENTRADAS, 100, N_SALIDAS]},\n",
        "    \"MLPDeep (10-10-10)\": {\"capas\": [N_ENTRADAS, 10, 10, 10, N_SALIDAS]},\n",
        "    \"MLPDeep (100-100-100)\": {\"capas\": [N_ENTRADAS, 100, 100, 100, N_SALIDAS]}\n",
        "}\n",
        "\n",
        "for nombre_modelo, config in modelos_mlp_config.items():\n",
        "    print(f\"\\nIniciando {N_CORRIDAS_MLP} corridas LOOCV para {nombre_modelo}...\")\n",
        "    for corrida in range(N_CORRIDAS_MLP):\n",
        "        y_preds_mlp = []\n",
        "        print(f\"  Corrida {corrida+1}/{N_CORRIDAS_MLP} para {nombre_modelo}...\")\n",
        "        for i in range(N_MUESTRAS):\n",
        "            # Separar datos\n",
        "            X_test_raw = X[i, :].reshape(1, -1)\n",
        "            y_test = y[i]\n",
        "            X_train_raw = np.delete(X, i, axis=0)\n",
        "            y_train = np.delete(y, i, axis=0)\n",
        "\n",
        "            # Normalizar\n",
        "            X_train_scaled, min_v, range_v = min_max_scaler(X_train_raw)\n",
        "            X_test_scaled = scale_test_data(X_test_raw, min_v, range_v)\n",
        "\n",
        "            # Entrenar y predecir\n",
        "            mlp = MLP_Desde_Cero(tam_capas=config[\"capas\"], epocas=50) # Menos épocas por la carga\n",
        "            mlp.fit(X_train_scaled, y_train)\n",
        "            pred = mlp.predict(X_test_scaled)\n",
        "            y_preds_mlp.append(pred[0])\n",
        "\n",
        "        # Calcular y guardar métricas para la corrida\n",
        "        metricas = calcular_metricas(y, np.array(y_preds_mlp))\n",
        "        resultados_loocv[nombre_modelo].append(metricas)\n",
        "    print(f\"LOOCV para {nombre_modelo} completado.\")\n",
        "\n",
        "# Celda 8: Cálculo de Estadísticas y Exportación para LOOCV\n",
        "print(\"\\n--- Calculando Estadísticas (Promedio, Mínimo, Máximo) para LOOCV ---\")\n",
        "estadisticas_finales_loocv = []\n",
        "\n",
        "for modelo, metricas_corridas in resultados_loocv.items():\n",
        "    # Para KNN, solo hay una corrida\n",
        "    if \"KNN\" in modelo and len(metricas_corridas) == 1:\n",
        "        metricas_corridas = metricas_corridas * N_CORRIDAS_MLP # Replicamos para consistencia estadística\n",
        "\n",
        "    df_metricas = pd.DataFrame(metricas_corridas)\n",
        "\n",
        "    promedio = df_metricas.mean().to_dict()\n",
        "    minimo = df_metricas.min().to_dict()\n",
        "    maximo = df_metricas.max().to_dict()\n",
        "\n",
        "    for metrica in [\"Accuracy\", \"Precision\", \"Recall\", \"Specificity\"]:\n",
        "        estadisticas_finales_loocv.append({\n",
        "            \"Validation\": \"Leave-One-Out\",\n",
        "            \"Algorithm\": modelo,\n",
        "            \"Metric\": metrica,\n",
        "            \"Mean\": promedio[metrica],\n",
        "            \"Min\": minimo[metrica],\n",
        "            \"Max\": maximo[metrica]\n",
        "        })\n",
        "\n",
        "df_estadisticas_loocv = pd.DataFrame(estadisticas_finales_loocv)\n",
        "print(df_estadisticas_loocv)\n",
        "\n",
        "# Exportar a CSV\n",
        "df_estadisticas_loocv.to_csv('loocv_results.csv', index=False)\n",
        "print(\"\\nResultados guardados en 'loocv_results.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3h5Xy2xMdkO",
        "outputId": "ba4357f3-af44-4171-bcc8-adcaf7605cd3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iniciando Ejecución con Leave-One-Out (LOOCV) ---\n",
            "ADVERTENCIA: Este proceso es muy lento y puede tardar varias horas, especialmente para los modelos MLP.\n",
            "\n",
            "Iniciando LOOCV para modelos KNN...\n",
            "LOOCV para KNN completado.\n",
            "\n",
            "Iniciando 30 corridas LOOCV para MLP (10 neuronas)...\n",
            "  Corrida 1/30 para MLP (10 neuronas)...\n",
            "  Corrida 2/30 para MLP (10 neuronas)...\n",
            "  Corrida 3/30 para MLP (10 neuronas)...\n",
            "  Corrida 4/30 para MLP (10 neuronas)...\n",
            "  Corrida 5/30 para MLP (10 neuronas)...\n",
            "  Corrida 6/30 para MLP (10 neuronas)...\n",
            "  Corrida 7/30 para MLP (10 neuronas)...\n",
            "  Corrida 8/30 para MLP (10 neuronas)...\n",
            "  Corrida 9/30 para MLP (10 neuronas)...\n",
            "  Corrida 10/30 para MLP (10 neuronas)...\n",
            "  Corrida 11/30 para MLP (10 neuronas)...\n",
            "  Corrida 12/30 para MLP (10 neuronas)...\n",
            "  Corrida 13/30 para MLP (10 neuronas)...\n",
            "  Corrida 14/30 para MLP (10 neuronas)...\n",
            "  Corrida 15/30 para MLP (10 neuronas)...\n",
            "  Corrida 16/30 para MLP (10 neuronas)...\n",
            "  Corrida 17/30 para MLP (10 neuronas)...\n",
            "  Corrida 18/30 para MLP (10 neuronas)...\n",
            "  Corrida 19/30 para MLP (10 neuronas)...\n",
            "  Corrida 20/30 para MLP (10 neuronas)...\n",
            "  Corrida 21/30 para MLP (10 neuronas)...\n",
            "  Corrida 22/30 para MLP (10 neuronas)...\n",
            "  Corrida 23/30 para MLP (10 neuronas)...\n",
            "  Corrida 24/30 para MLP (10 neuronas)...\n",
            "  Corrida 25/30 para MLP (10 neuronas)...\n",
            "  Corrida 26/30 para MLP (10 neuronas)...\n",
            "  Corrida 27/30 para MLP (10 neuronas)...\n",
            "  Corrida 28/30 para MLP (10 neuronas)...\n",
            "  Corrida 29/30 para MLP (10 neuronas)...\n",
            "  Corrida 30/30 para MLP (10 neuronas)...\n",
            "LOOCV para MLP (10 neuronas) completado.\n",
            "\n",
            "Iniciando 30 corridas LOOCV para MLP (100 neuronas)...\n",
            "  Corrida 1/30 para MLP (100 neuronas)...\n",
            "  Corrida 2/30 para MLP (100 neuronas)...\n",
            "  Corrida 3/30 para MLP (100 neuronas)...\n",
            "  Corrida 4/30 para MLP (100 neuronas)...\n",
            "  Corrida 5/30 para MLP (100 neuronas)...\n",
            "  Corrida 6/30 para MLP (100 neuronas)...\n",
            "  Corrida 7/30 para MLP (100 neuronas)...\n",
            "  Corrida 8/30 para MLP (100 neuronas)...\n",
            "  Corrida 9/30 para MLP (100 neuronas)...\n",
            "  Corrida 10/30 para MLP (100 neuronas)...\n",
            "  Corrida 11/30 para MLP (100 neuronas)...\n",
            "  Corrida 12/30 para MLP (100 neuronas)...\n",
            "  Corrida 13/30 para MLP (100 neuronas)...\n",
            "  Corrida 14/30 para MLP (100 neuronas)...\n",
            "  Corrida 15/30 para MLP (100 neuronas)...\n",
            "  Corrida 16/30 para MLP (100 neuronas)...\n",
            "  Corrida 17/30 para MLP (100 neuronas)...\n",
            "  Corrida 18/30 para MLP (100 neuronas)...\n",
            "  Corrida 19/30 para MLP (100 neuronas)...\n",
            "  Corrida 20/30 para MLP (100 neuronas)...\n",
            "  Corrida 21/30 para MLP (100 neuronas)...\n",
            "  Corrida 22/30 para MLP (100 neuronas)...\n",
            "  Corrida 23/30 para MLP (100 neuronas)...\n",
            "  Corrida 24/30 para MLP (100 neuronas)...\n",
            "  Corrida 25/30 para MLP (100 neuronas)...\n",
            "  Corrida 26/30 para MLP (100 neuronas)...\n",
            "  Corrida 27/30 para MLP (100 neuronas)...\n",
            "  Corrida 28/30 para MLP (100 neuronas)...\n",
            "  Corrida 29/30 para MLP (100 neuronas)...\n",
            "  Corrida 30/30 para MLP (100 neuronas)...\n",
            "LOOCV para MLP (100 neuronas) completado.\n",
            "\n",
            "Iniciando 30 corridas LOOCV para MLPDeep (10-10-10)...\n",
            "  Corrida 1/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 2/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 3/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 4/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 5/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 6/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 7/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 8/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 9/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 10/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 11/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 12/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 13/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 14/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 15/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 16/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 17/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 18/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 19/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 20/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 21/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 22/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 23/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 24/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 25/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 26/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 27/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 28/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 29/30 para MLPDeep (10-10-10)...\n",
            "  Corrida 30/30 para MLPDeep (10-10-10)...\n",
            "LOOCV para MLPDeep (10-10-10) completado.\n",
            "\n",
            "Iniciando 30 corridas LOOCV para MLPDeep (100-100-100)...\n",
            "  Corrida 1/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 2/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 3/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 4/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 5/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 6/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 7/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 8/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 9/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 10/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 11/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 12/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 13/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 14/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 15/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 16/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 17/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 18/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 19/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 20/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 21/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 22/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 23/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 24/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 25/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 26/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 27/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 28/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 29/30 para MLPDeep (100-100-100)...\n",
            "  Corrida 30/30 para MLPDeep (100-100-100)...\n",
            "LOOCV para MLPDeep (100-100-100) completado.\n",
            "\n",
            "--- Calculando Estadísticas (Promedio, Mínimo, Máximo) para LOOCV ---\n",
            "       Validation              Algorithm       Metric      Mean       Min  \\\n",
            "0   Leave-One-Out      MLP (10 neuronas)     Accuracy  0.753846  0.753846   \n",
            "1   Leave-One-Out      MLP (10 neuronas)    Precision  0.753846  0.753846   \n",
            "2   Leave-One-Out      MLP (10 neuronas)       Recall  1.000000  1.000000   \n",
            "3   Leave-One-Out      MLP (10 neuronas)  Specificity  0.000000  0.000000   \n",
            "4   Leave-One-Out     MLP (100 neuronas)     Accuracy  0.753846  0.753846   \n",
            "5   Leave-One-Out     MLP (100 neuronas)    Precision  0.753846  0.753846   \n",
            "6   Leave-One-Out     MLP (100 neuronas)       Recall  1.000000  1.000000   \n",
            "7   Leave-One-Out     MLP (100 neuronas)  Specificity  0.000000  0.000000   \n",
            "8   Leave-One-Out     MLPDeep (10-10-10)     Accuracy  0.753846  0.753846   \n",
            "9   Leave-One-Out     MLPDeep (10-10-10)    Precision  0.753846  0.753846   \n",
            "10  Leave-One-Out     MLPDeep (10-10-10)       Recall  1.000000  1.000000   \n",
            "11  Leave-One-Out     MLPDeep (10-10-10)  Specificity  0.000000  0.000000   \n",
            "12  Leave-One-Out  MLPDeep (100-100-100)     Accuracy  0.753846  0.753846   \n",
            "13  Leave-One-Out  MLPDeep (100-100-100)    Precision  0.753846  0.753846   \n",
            "14  Leave-One-Out  MLPDeep (100-100-100)       Recall  1.000000  1.000000   \n",
            "15  Leave-One-Out  MLPDeep (100-100-100)  Specificity  0.000000  0.000000   \n",
            "16  Leave-One-Out              KNN (k=3)     Accuracy  0.851282  0.851282   \n",
            "17  Leave-One-Out              KNN (k=3)    Precision  0.888158  0.888158   \n",
            "18  Leave-One-Out              KNN (k=3)       Recall  0.918367  0.918367   \n",
            "19  Leave-One-Out              KNN (k=3)  Specificity  0.645833  0.645833   \n",
            "20  Leave-One-Out              KNN (k=5)     Accuracy  0.861538  0.861538   \n",
            "21  Leave-One-Out              KNN (k=5)    Precision  0.875000  0.875000   \n",
            "22  Leave-One-Out              KNN (k=5)       Recall  0.952381  0.952381   \n",
            "23  Leave-One-Out              KNN (k=5)  Specificity  0.583333  0.583333   \n",
            "24  Leave-One-Out             KNN (k=27)     Accuracy  0.815385  0.815385   \n",
            "25  Leave-One-Out             KNN (k=27)    Precision  0.806630  0.806630   \n",
            "26  Leave-One-Out             KNN (k=27)       Recall  0.993197  0.993197   \n",
            "27  Leave-One-Out             KNN (k=27)  Specificity  0.270833  0.270833   \n",
            "\n",
            "         Max  \n",
            "0   0.753846  \n",
            "1   0.753846  \n",
            "2   1.000000  \n",
            "3   0.000000  \n",
            "4   0.753846  \n",
            "5   0.753846  \n",
            "6   1.000000  \n",
            "7   0.000000  \n",
            "8   0.753846  \n",
            "9   0.753846  \n",
            "10  1.000000  \n",
            "11  0.000000  \n",
            "12  0.753846  \n",
            "13  0.753846  \n",
            "14  1.000000  \n",
            "15  0.000000  \n",
            "16  0.851282  \n",
            "17  0.888158  \n",
            "18  0.918367  \n",
            "19  0.645833  \n",
            "20  0.861538  \n",
            "21  0.875000  \n",
            "22  0.952381  \n",
            "23  0.583333  \n",
            "24  0.815385  \n",
            "25  0.806630  \n",
            "26  0.993197  \n",
            "27  0.270833  \n",
            "\n",
            "Resultados guardados en 'loocv_results.csv'\n"
          ]
        }
      ]
    }
  ]
}